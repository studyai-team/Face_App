# FaceApp

Fast Bi-layer Neural Synthesis of One-Shot Realistic Head Avatars(https://github.com/saic-violet/bilayer-model) をbaseに出力の処理を追加した  
## プログラムの要件
入力:  
サイズが256 x 256以上の画像
プログラム内部で顔の中心を真ん中に持ってきて256x256で切り取る処理が入るため、大きい方が望ましい  
出力:  
256 x 256の画像

## 使用方法
1. ``pip install -r requirements.txt``
2. (https://drive.google.com/drive/folders/11SwIYnk3KY61d8qa17Nlb0BN9j57B3L6) から訓練済みモデルをダウンロードして、bilayer-modelにpretrained_weightsとrunsを配置
3. examples/imagesに変換したい画像を配置(複数の画像を配置可能)
4. ``python create.py``をすると、examples/resultsに画像が出力される(missing keyとpytorchのdeprecated errorが出るが気にしないでよい)


### 生成画像の説明  
source -> 顔の中心を画像の真ん中に持ってくる前処理を行った後の入力データ  
hf -> 高周波領域の画像(ネットワーク内部で使用している)  
target -> 真顔または笑顔の表情のランドマーク  
pred -> 生成画像  
cropped -> 生成画像を基に画像の意味のある部分を切り取った画像(最終的な出力)  


## 今回のプログラムを実装するにあたって行ったこと
1. FaGANを実装した
表情変換を行うGANであるFaGANを実装した。実際に訓練を回したところ、かなり多くのコストがかかることがわかり、1からモデルを訓練することは困難だとわかった。  
(PCスペック:  
CPU種類：第9世代 インテル Core i9 9900K(Coffee Lake Refresh)  
コア数：8コア CPU　スコア：18896  
メモリ容量：32GB  
ストレージ容量：HDD：2TB/SSD：512GB  
GeForce RTX 2080
において一つのバッチの学習に約5秒かかり、データセット全てを利用するとすると、バッチ数が約15万個あるので1epochは10日ほどかかる。また、論文にどれくらい学習を回したかの記載がないのでこれで十分かも不明。
本来は複数のGPUを利用して学習するものだと思われる)。
2. bilayer-modelを利用し、画像を生成した(本実装)
FaGANを訓練している最中に商用利用可能なプログラムコード及びpretrained modelがある本実装が公開された。実際に利用したところ、いくつかの問題点はあるものの、表情変換に成功した。

## 本実装の課題点
顔が大きく傾いていると表情変換がうまくいかない
- 本研究は本来はある表情を利用して、その画像をアバターとして表情を変換するものなので、入力として大きな傾きがある顔の画像は考慮されていないと考えられる。仮に表情変換を大きくしてもよい結果を生成したい場合は、
学習の段階から角度をつけた画像を利用して学習することが望ましいと思われる。しかし、本来のタスクの難易度が上昇するYouTubeのインタビューなどの動画からデータセットを作成する必要があり、難易度が上昇すると思われる。

服の色が黒くなる
- 髪の色との区別が難しい可能性がある。また、本研究では顔のランドマークを利用しているのに対して服のランドマークや輪郭の情報は利用していないため、服に関する画像生成には強くないと考えられる。

顔の輪郭の部分がぼやける
- segmentationのAPIを利用すればこの問題は改善できることがわかった(remove.bg https://www.remove.bg/ja/api)。
しかし今回は教育目的のため利用出来ないので無料のモデルを探したが、十分なクオリティーのものは見つからなかった
(例: https://blog.tensorflow.org/2019/11/updated-bodypix-2.html 一枚目の動画で見ると精度がよく見えるが、二枚目の動画を見ると、一つ一つの画像の例だと荒い推論しかできていないことがわかる)。
また、この研究のデモンストレーション(https://www.youtube.com/watch?v=54tji11VhOI&feature=youtu.be)によると、輪郭が黒くなってしまっている現象が確認出来た。このような輪郭の曖昧さの改善は今後の研究課題と言える。

VoxCeleb1 datasetを利用して訓練している関係上、生成された画像は西洋人風になる

- アジア系の顔のデータセットだとAsianFaceDataset(AFD)などがあるが、このタスクにおいては同じ人の連続した顔のデータが必要であり、AFDは同じ人の顔が複数あるものの、連続した顔のデータでない(服装が変わっていたりする)ので利用出来ない。
他に利用出来るアジア系の顔のデータセットは見つからなかった。  
Voxceleb1の詳細は以下のサイトに記載されている(http://www.robots.ox.ac.uk/~vgg/data/voxceleb/vox1.html)  
また、実際にFaR-GANで使用したデータセットは、(http://www.robots.ox.ac.uk/~vgg/research/CMBiometrics/ で使用されていたVoxceleb1のデータセットから1fpsで画像を切り出したものである。)
アジア系の顔のデータセットを入手出来た場合、学習済みモデルを利用してFine tuningすることで比較的に簡単に学習が出来ると考えられる。  
Fine tuningする際は本実験で使用した、Fast Bi-layer Neural Synthesis of One-Shot Realistic Head Avatarsのモデルにおいて、始めに表情を変化させたい顔と表情を入力して学習しているので、仮に入力の画像をアジア系の顔のデータセットに変更して利用する場合はモデル全体を学習する方がよいと考えられる。  
